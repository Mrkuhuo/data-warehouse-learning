# 同步MySQL仓库信息表（全量模式）到Doris ods层
env {
  # 并行度设置
  parallelism = 1
  
  # 作业模式：BATCH表示批处理模式，适合全量同步
  job.mode = "BATCH"
}

source {
  # 使用JDBC连接器从MySQL读取数据
  Jdbc {
    url = "jdbc:mysql://192.168.241.128:3306/gmall?useUnicode=true&characterEncoding=UTF-8&serverTimezone=Asia/Shanghai"
    driver = "com.mysql.cj.jdbc.Driver"
    user = "root"
    password = ""
    query = "select * from ware_info"
    
    # 结果表名，用于后续处理
    result_table_name = "mysql_source"
  }
}

# 数据转换处理
transform {
  # 使用SQL进行数据转换
  Sql {
    source_table_name = "mysql_source"
    result_table_name = "doris_sink_data"
    
    # 添加分区字段k1，用于Doris表分区
    query = """
      select 
        id,
        date_format(create_time,'%Y-%m-%d') as k1,
        name,
        address,
        areacode,
        create_time
      from mysql_source
    """
  }
}

sink {
  # 使用Doris连接器写入数据
  Doris {
    # 连接信息
    fenodes = "192.168.241.128:8030"
    username = "root"
    password = ""
    table.identifier = "ods.ods_ware_info_full"
    
    # 数据源
    source_table_name = "doris_sink_data"
    
    # 导入参数设置
    sink.properties {
      format = "json"
      read_json_by_line = "true"
      strip_outer_array = "false"
      
      # 导入模式：APPEND表示追加模式
      merge_type = "APPEND"
    }
    
    # 批量写入设置
    sink.buffer-size = 1000
    sink.buffer-count = 3
    sink.max-retries = 3
  }
} 