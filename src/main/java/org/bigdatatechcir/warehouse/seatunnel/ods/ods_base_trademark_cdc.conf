#同步MySQL品牌表（CDC模式）到Doris ods层
env {
  # 环境配置
  parallelism = 8                     # 增加并行度以提高吞吐量
  job.mode = "STREAMING"              # 使用流式处理模式进行实时同步
  checkpoint.interval = 10000         # 检查点间隔，单位毫秒

  # 限流配置 - 避免对源数据库造成过大压力
  read_limit.bytes_per_second = 10000000  # 每秒读取字节数限制，约10MB/s
  read_limit.rows_per_second = 1000       # 每秒读取行数限制

  # 本地检查点配置
  execution.checkpoint.data-uri = "file:///opt/seatunnel/checkpoints"
  execution.checkpoint.max-concurrent = 1  # 最大并发检查点数

  # 性能优化参数
  execution.buffer-timeout = 5000          # 缓冲超时时间(毫秒)
  execution.jvm-options = "-Xms4g -Xmx8g -XX:+UseG1GC -XX:MaxGCPauseMillis=100"
}

source {
  MySQL-CDC {
    # 基本连接配置
    # server-id = 5652-5657             # MySQL复制客户端的唯一ID范围
    username = "root"                # 数据库用户名
    password = ""                # 数据库密码
    table-names = ["gmall.base_trademark"]  # 要同步的表
    base-url = "jdbc:mysql://192.168.241.128:3306/gmall?useUnicode=true&characterEncoding=UTF-8&serverTimezone=Asia/Shanghai"

    # CDC 特有配置
    schema-changes.enabled = true     # 启用架构变更捕获
    server-time-zone = "Asia/Shanghai"  # 服务器时区

    # 性能优化配置
    snapshot.mode = "initial"         # 初始快照模式
    snapshot.fetch.size = 10000       # 快照获取大小
    chunk.size.rows = 8096            # 分块大小，用于并行快照
    connection.pool.size = 10         # 连接池大小

    # 高级配置
    include.schema.changes = true     # 包含架构变更事件
    scan.startup.mode = "initial"     # 启动模式：initial(全量+增量)
    scan.incremental.snapshot.chunk.size = 8096  # 增量快照分块大小
    debezium.min.row.count.to.stream.results = 1000  # 流式结果的最小行数

    # 容错配置
    connect.timeout = 30000           # 连接超时时间(毫秒)
    connect.max-retries = 3           # 最大重试次数

    # 输出表名
    result_table_name = "mysql_cdc_source"
  }
}

# 可选的转换逻辑，如果需要对数据进行处理
transform {
  Sql {
    source_table_name = "mysql_cdc_source"
    result_table_name = "doris_sink_data"

    # 根据需要转换字段，这里添加了一个分区字段k1
    query = """
      select
        id,
        tm_name,
        logo_url
      from mysql_cdc_source
    """
  }
}

sink {
  Doris {
    # 基本连接配置
    source_table_name = "doris_sink_data"  # 或直接使用 "mysql_cdc_source"
    fenodes = "192.168.241.128:8030"
    username = "root"
    password = ""
    table.identifier = "ods.ods_base_trademark_full"  # Doris目标表

    # 事务和标签配置
    sink.enable-2pc = "true"          # 启用两阶段提交，确保一致性
    sink.label-prefix = "cdc_sync"    # 导入标签前缀

    # 写入模式配置
    sink.properties {
      format = "json"
      read_json_by_line = "true"
      column_separator = "\t"         # 列分隔符
      line_delimiter = "\n"           # 行分隔符
      max_filter_ratio = "0.1"        # 允许的最大错误率

      # CDC特有配置 - 处理不同操作类型
      # 使用Doris的UPSERT模式处理CDC事件
      merge_type = "MERGE"            # 合并类型：APPEND或MERGE
      delete_enable = "true"          # 启用删除操作
    }

    # 性能优化配置
    sink.buffer-size = 10000          # 缓冲区大小
    sink.buffer-count = 3             # 缓冲区数量
    sink.flush.interval-ms = 5000     # 刷新间隔
    sink.max-retries = 3              # 最大重试次数
    sink.parallelism = 8              # 写入并行度

    # Doris连接优化
    doris.config = {
      format = "json"
      read_json_by_line = "true"
      request_connect_timeout_ms = "5000"  # 连接超时
      request_timeout_ms = "30000"         # 请求超时
      request_tablet_size = "5"            # 每个请求的tablet数量
    }
  }
} 